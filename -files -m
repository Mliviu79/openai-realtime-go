warning: in the working copy of 'go.mod', LF will be replaced by CRLF the next time Git touches it
warning: in the working copy of 'go.sum', LF will be replaced by CRLF the next time Git touches it
[1mdiff --git a/CHANGES.md b/CHANGES.md[m
[1mindex 9373950..f3c0a90 100644[m
[1m--- a/CHANGES.md[m
[1m+++ b/CHANGES.md[m
[36m@@ -2,7 +2,16 @@[m
 [m
 This document outlines the major changes and improvements made in this fork of the [WqyJh/go-openai-realtime](https://github.com/WqyJh/go-openai-realtime) library.[m
 [m
[31m-## Latest Updates (March 2024)[m
[32m+[m[32m## Latest Updates (March 2025)[m
[32m+[m
[32m+[m[32m- **OpenAI Realtime API Update**: Added support for the latest OpenAI Realtime API features:[m
[32m+[m[32m  - Added dedicated support for transcription sessions via the new `/realtime/transcription_sessions` endpoint[m
[32m+[m[32m  - Added ability to update transcription sessions via the `transcription_session.update` event[m
[32m+[m[32m  - Added ability to request log probabilities in transcription results[m
[32m+[m[32m  - Added new transcription models: `gpt-4o-transcribe` and `gpt-4o-mini-transcribe`[m
[32m+[m[32m  - Added new voice options: `fable`, `onyx`, and `nova`[m
[32m+[m[32m  - Added semantic VAD support with eagerness levels for more natural turn detection[m
[32m+[m[32m  - Added input audio noise reduction for near-field and far-field microphones[m
 [m
 - **Updated Dependencies**: Modified `go.mod` and `go.sum` to update dependencies.[m
 - **Gitignore Improvements**: Added additional patterns to `.gitignore`.[m
[1mdiff --git a/README.md b/README.md[m
[1mindex 6c6296a..b1cae50 100644[m
[1m--- a/README.md[m
[1m+++ b/README.md[m
[36m@@ -59,6 +59,7 @@[m [mimport ([m
 	"time"[m
 [m
 	"github.com/Mliviu79/openai-realtime-go/messages/incoming"[m
[32m+[m	[32m"github.com/Mliviu79/openai-realtime-go/messages/types"[m
 	"github.com/Mliviu79/openai-realtime-go/messaging"[m
 	"github.com/Mliviu79/openai-realtime-go/openaiClient"[m
 	"github.com/Mliviu79/openai-realtime-go/session"[m
[36m@@ -89,10 +90,20 @@[m [mfunc main() {[m
 	msgClient := messaging.NewClient(conn)[m
 [m
 	// Send a text message[m
[31m-	err = msgClient.SendTextMessage(ctx, "Tell me about the OpenAI Realtime API", nil)[m
[32m+[m	[32merr = msgClient.SendText(ctx, "Tell me about the OpenAI Realtime API")[m
 	if err != nil {[m
 		log.Fatalf("Failed to send message: %v", err)[m
 	}[m
[32m+[m[41m	[m
[32m+[m	[32m// Request the model to generate a response[m
[32m+[m	[32m// This step is required - without it, no response will be generated[m
[32m+[m	[32mresponseConfig := &types.ResponseConfig{[m
[32m+[m		[32mModalities: []session.Modality{session.ModalityText},[m
[32m+[m	[32m}[m
[32m+[m	[32merr = msgClient.SendResponseCreate(ctx, responseConfig)[m
[32m+[m	[32mif err != nil {[m
[32m+[m		[32mlog.Fatalf("Failed to request response: %v", err)[m
[32m+[m	[32m}[m
 [m
 	// Read and process messages[m
 	fmt.Println("Response:")[m
[36m@@ -106,7 +117,7 @@[m [mfunc main() {[m
 		switch m := msg.(type) {[m
 		case *incoming.ResponseTextDeltaMessage:[m
 			// Print text deltas as they arrive[m
[31m-			fmt.Print(m.Delta.Text)[m
[32m+[m			[32mfmt.Print(m.Delta)[m
 		case *incoming.ResponseDoneMessage:[m
 			// End of the response[m
 			fmt.Println("\nResponse complete")[m
[36m@@ -116,6 +127,27 @@[m [mfunc main() {[m
 }[m
 ```[m
 [m
[32m+[m[32m## Important: Two-Step Process for Getting Responses[m
[32m+[m
[32m+[m[32mThe OpenAI Realtime API uses a two-step process to get a response from the model:[m
[32m+[m
[32m+[m[32m1. **Send your message(s)** using methods like `SendText`, `SendAudio`, etc.[m
[32m+[m[32m2. **Request a response** using `SendResponseCreate` with a configuration object[m
[32m+[m
[32m+[m[32mThis design enables powerful capabilities:[m
[32m+[m[32m- You can send multiple messages before requesting a response[m
[32m+[m[32m- You can configure exactly how the model should respond (modalities, temperature, etc.)[m
[32m+[m[32m- You can control precisely when the model should start generating a response[m
[32m+[m
[32m+[m[32m**Without the second step, the model will not generate any response to your messages.**[m
[32m+[m
[32m+[m[32mThe `SendResponseCreate` method takes a `ResponseConfig` object that can include:[m
[32m+[m[32m- Which modalities to use for the response (text, audio)[m
[32m+[m[32m- Voice options for audio responses[m
[32m+[m[32m- Temperature and other generation parameters[m
[32m+[m[32m- Tools the model can use[m
[32m+[m[32m- Optional system instructions[m
[32m+[m
 ## Session Management[m
 [m
 You can create and manage sessions either through the REST API or WebSocket messages:[m
[36m@@ -237,6 +269,74 @@[m [mcreateReq := &session.CreateRequest{[m
 }[m
 ```[m
 [m
[32m+[m[32m### Transcription Sessions[m
[32m+[m
[32m+[m[32mThe library supports OpenAI's dedicated transcription sessions for real-time speech-to-text:[m
[32m+[m
[32m+[m[32m```go[m
[32m+[m[32m// Configure transcription session[m
[32m+[m[32minputFormat := session.AudioFormatPCM16[m
[32m+[m[32mtranscriptionModel := session.TranscriptionModelGPT4oTranscribe[m
[32m+[m
[32m+[m[32m// Optional: request log probabilities[m[41m [m
[32m+[m[32mincludes := []session.TranscriptionSessionInclude{[m
[32m+[m[32m    session.TranscriptionSessionIncludeLogprobs,[m
[32m+[m[32m}[m
[32m+[m[32mincludeSlice := make([]session.TranscriptionSessionInclude, len(includes))[m
[32m+[m[32mcopy(includeSlice, includes)[m
[32m+[m
[32m+[m[32m// Create a transcription session[m
[32m+[m[32mcreateReq := &session.CreateTranscriptionSessionRequest{[m
[32m+[m[32m    TranscriptionSessionRequest: session.TranscriptionSessionRequest{[m
[32m+[m[32m        InputAudioFormat: &inputFormat,[m
[32m+[m[32m        InputAudioTranscription: &session.InputAudioTranscription{[m
[32m+[m[32m            Model: transcriptionModel,[m
[32m+[m[32m            Language: "en",  // Optional language hint[m
[32m+[m[32m            Prompt: "Technical vocabulary",  // Optional domain hint[m
[32m+[m[32m        },[m
[32m+[m[32m        Include: &includeSlice,  // Optional: include log probabilities[m
[32m+[m[32m    },[m
[32m+[m[32m}[m
[32m+[m
[32m+[m[32m// Create the session via the API[m
[32m+[m[32msessionResp, err := client.CreateTranscriptionSession(ctx, createReq)[m
[32m+[m[32mif err != nil {[m
[32m+[m[32m    log.Fatalf("Failed to create transcription session: %v", err)[m
[32m+[m[32m}[m
[32m+[m
[32m+[m[32m// Connect to the transcription session[m
[32m+[m[32mconn, err := client.Connect(ctx,[m
[32m+[m[32m    openaiClient.WithModel(session.GPT4oRealtimePreview),[m
[32m+[m[32m    openaiClient.WithSessionID(sessionResp.ID),[m
[32m+[m[32m    openaiClient.WithTranscriptionSession())  // Special flag for transcription sessions[m
[32m+[m
[32m+[m[32m// Update the transcription session with new settings while connected[m
[32m+[m[32mnoiseReduction := &session.InputAudioNoiseReduction{[m
[32m+[m[32m    Type: session.NoiseReductionTypeNearField,[m
[32m+[m[32m}[m
[32m+[m
[32m+[m[32mturnDetection := &session.TurnDetection{[m
[32m+[m[32m    Type:      session.TurnDetectionTypeSemanticVad,[m
[32m+[m[32m    Eagerness: session.EagernessLevelHigh,[m
[32m+[m[32m}[m
[32m+[m
[32m+[m[32mupdateReq := session.TranscriptionSessionRequest{[m
[32m+[m[32m    InputAudioNoiseReduction: noiseReduction,[m
[32m+[m[32m    TurnDetection:            turnDetection,[m
[32m+[m[32m}[m
[32m+[m
[32m+[m[32m// Send the update[m
[32m+[m[32merr = msgClient.SendTranscriptionSessionUpdate(ctx, updateReq)[m
[32m+[m[32mif err != nil {[m
[32m+[m[32m    log.Fatalf("Failed to update transcription session: %v", err)[m
[32m+[m[32m}[m
[32m+[m
[32m+[m[32m// Now send audio and receive transcriptions[m
[32m+[m[32m// ...[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32mSee the 